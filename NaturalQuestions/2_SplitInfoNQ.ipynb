{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_nq_path = 'C:\\\\Users\\\\Matheus\\\\Desktop\\\\Pós Graduação\\\\NLP\\\\Projeto\\\\Datasets\\\\NATURAL_QUESTIONS\\\\clean_nq_format.jsonl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import pdb\n",
    "import re\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkstring(text,tokens_length = 200): \n",
    "    text_tokens = [token for token in text.split(' ')]\n",
    "    tokens_length = 200\n",
    "    n_chunks = math.ceil(len(text_tokens)/tokens_length)\n",
    "    chunck_no_context = [' '.join(text_tokens[(0+i*tokens_length): (tokens_length-1+i*tokens_length)]) for i in range(0, n_chunks)]\n",
    "\n",
    "    return chunck_no_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nq_dict_to_df():\n",
    "    \n",
    "    df_doc_text = pd.DataFrame(columns=['ID','DOC_TEXT'])\n",
    "    df_long_answer = pd.DataFrame(columns=['ID','LONG_ANSWER','START_LA','END_LA'])\n",
    "    df_short_answer = pd.DataFrame(columns=['ID','SHORT_ANSWER','START_SA','END_SA'])\n",
    "    df_question = pd.DataFrame(columns=['ID','QUESTION'])\n",
    "    df_infos = pd.DataFrame(columns=['ID','DOCUMENT_URL','YES_NO_ANSWER'])\n",
    "    \n",
    "    with jsonlines.open(clean_nq_path) as reader:\n",
    "        for row in reader:\n",
    "            \n",
    "            # Document Text\n",
    "            doctext_chuncks = chunkstring(row['document_text'])\n",
    "            for chunk in doctext_chuncks:\n",
    "                df_doc_text = df_doc_text.append(pd.Series([row['example_id'],chunk], index=df_doc_text.columns), ignore_index=True)\n",
    "            \n",
    "            #long Answer\n",
    "            start_token = row['annotations'][0]['long_answer']['start_token']\n",
    "            end_token = row['annotations'][0]['long_answer']['end_token']\n",
    "            long_answer = \" \".join(row['document_text'].split(\" \")[start_token:end_token])\n",
    "            long_answer_chunks = chunkstring(long_answer)\n",
    "            for chunk in long_answer_chunks:\n",
    "                df_long_answer = df_long_answer.append(pd.Series([row['example_id'],chunk,start_token,end_token], index=df_long_answer.columns), ignore_index=True)\n",
    "            \n",
    "            # Short Answers\n",
    "            short_answers = row['annotations'][0]['short_answers']\n",
    "            for sa in short_answers:\n",
    "                start_token = sa['start_token']\n",
    "                end_token = sa['end_token']\n",
    "                short_answer = \" \".join(row['document_text'].split(\" \")[start_token:end_token])\n",
    "                df_short_answer = df_short_answer.append(pd.Series([row['example_id'],short_answer,start_token,end_token], index=df_short_answer.columns), ignore_index=True)\n",
    "\n",
    "            # Questions\n",
    "            df_question = df_question.append(pd.Series([row['example_id'],row['question_text']], index=df_question.columns), ignore_index=True)\n",
    "             \n",
    "            # Infos\n",
    "            df_infos = df_infos.append(pd.Series([row['example_id'],row['document_url'],row['annotations'][0]['yes_no_answer']], index=df_infos.columns), ignore_index=True)\n",
    "    \n",
    "        \n",
    "    return df_doc_text,df_long_answer,df_short_answer,df_question,df_infos\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_in_tables(df_doc_text,df_long_answer,df_short_answer,df_question,df_infos):\n",
    "    # Document Text\n",
    "    compression_opts = dict(method='zip', archive_name='nq_doc_text.csv') \n",
    "    df_doc_text.to_csv('nq_doc_text.zip', index=False,compression=compression_opts)\n",
    "\n",
    "    # long Answer\n",
    "    compression_opts = dict(method='zip', archive_name='nq_long_answer.csv') \n",
    "    df_long_answer.to_csv('nq_long_answer.zip', index=False,compression=compression_opts)\n",
    "    \n",
    "    # Short Answers\n",
    "    compression_opts = dict(method='zip', archive_name='nq_short_answer.csv') \n",
    "    df_short_answer.to_csv('nq_short_answer.zip', index=False,compression=compression_opts)\n",
    "    \n",
    "    # Questions\n",
    "    compression_opts = dict(method='zip', archive_name='nq_question.csv') \n",
    "    df_question.to_csv('nq_question.zip', index=False,compression=compression_opts)\n",
    "    \n",
    "    # Infos\n",
    "    compression_opts = dict(method='zip', archive_name='nq_infos.csv') \n",
    "    df_infos.to_csv('nq_infos.zip', index=False,compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_text,df_long_answer,df_short_answer,df_question,df_infos = nq_dict_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_in_tables(df_doc_text,df_long_answer,df_short_answer,df_question,df_infos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
