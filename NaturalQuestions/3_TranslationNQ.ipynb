{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_TranslationNQ.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"60d48ababbdb4038aca3bff46b036354":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9d53a42334e74a6e834ce3a368c465db","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b5e672767cc545d9a2d6ffab82baa80a","IPY_MODEL_44356847063d45efb3398613698d2dc5"]}},"9d53a42334e74a6e834ce3a368c465db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"b5e672767cc545d9a2d6ffab82baa80a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b7884a11c6cc4f71a3f864324f8c2011","_dom_classes":[],"description":"Epoch 1: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":2,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_88967357168f41ae972bfb5dd1e1ae06"}},"44356847063d45efb3398613698d2dc5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_88606b74e3da433e8b75de83438a2538","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [00:04&lt;00:00,  2.12s/it, avg_val_bleu=0.748, gpu_usage=56%, loss=4.566, v_num=0]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6489f51569ad4f49838c89ccfd9bfde3"}},"b7884a11c6cc4f71a3f864324f8c2011":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"88967357168f41ae972bfb5dd1e1ae06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88606b74e3da433e8b75de83438a2538":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6489f51569ad4f49838c89ccfd9bfde3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c25956b7d7114448b26f9fe9636c6416":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_90371c0ef86f4cf2995cec230fef22f4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6286f2bcfd654f1790948d210a8f38e8","IPY_MODEL_21eb9d74d6ef47cab4e4924c30c612a5"]}},"90371c0ef86f4cf2995cec230fef22f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"6286f2bcfd654f1790948d210a8f38e8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_abb2c53ba7124b37b2f221c0cfbfb2fb","_dom_classes":[],"description":"Validating: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_90b23e6a949d4ca7996bc22f22b69080"}},"21eb9d74d6ef47cab4e4924c30c612a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_650ac27941b24202b5a9d7f4d0f4a8df","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:02&lt;00:00,  2.69s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8819c1b8ff9c492aba52f0ee5a03e69d"}},"abb2c53ba7124b37b2f221c0cfbfb2fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"90b23e6a949d4ca7996bc22f22b69080":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"650ac27941b24202b5a9d7f4d0f4a8df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8819c1b8ff9c492aba52f0ee5a03e69d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"171c12fbf43a474ebaaebd765ba89737":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_cffdf5d406e8449899c50a00742446f0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8908dc493cb6476ab38f1290e650d45b","IPY_MODEL_c1f99fc5893c4698906421c9f6eae268"]}},"cffdf5d406e8449899c50a00742446f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"8908dc493cb6476ab38f1290e650d45b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6437b39e3e8f471393480309381bf975","_dom_classes":[],"description":"Validation sanity check:   0%","_model_name":"FloatProgressModel","bar_style":"danger","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05b4d9d74bfc47389b3b801f89e6923b"}},"c1f99fc5893c4698906421c9f6eae268":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d3c8fd8bb1ac4ca4b940115aabc84ac1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/2 [00:04&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc1b05f0ad154d89b33396f2a03df164"}},"6437b39e3e8f471393480309381bf975":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"05b4d9d74bfc47389b3b801f89e6923b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d3c8fd8bb1ac4ca4b940115aabc84ac1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bc1b05f0ad154d89b33396f2a03df164":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"eec4419ddcc449d791aa84f6562d2baf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_481d3cdd37144956b082a29148db9383","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6b39770b9f154effb9b31498363bef03","IPY_MODEL_89a6b3a820614ad897d6184f52d304da"]}},"481d3cdd37144956b082a29148db9383":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"6b39770b9f154effb9b31498363bef03":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_91ea95332b7d4db1a268119243fc2f5d","_dom_classes":[],"description":"Epoch 1:   5%","_model_name":"FloatProgressModel","bar_style":"danger","max":3282,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":150,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d6daad420df4a1f8843850507155de2"}},"89a6b3a820614ad897d6184f52d304da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_126891e4ad494cdb8717cafc6c1fdb26","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 150/3282 [01:59&lt;41:26,  1.26it/s, gpu_usage=96%, loss=0.505, v_num=1]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9977b918bb1e4554b7990d964d88a2bb"}},"91ea95332b7d4db1a268119243fc2f5d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5d6daad420df4a1f8843850507155de2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"126891e4ad494cdb8717cafc6c1fdb26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9977b918bb1e4554b7990d964d88a2bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qozxY-E_7kU2","colab_type":"text"},"source":["# Projeto: Dataset MS Marco Traduzido para Português\n","### Autores : Graziella Cardoso Bonadia e Matheus Gustavo Alves Sasso\n"]},{"cell_type":"code","metadata":{"id":"WsFz3qIyuxEw","colab_type":"code","colab":{}},"source":["#@title Configurações gerais\n","experiment_name = 'NaturalQuestionsPortuguese'  #@param {type:\"string\"}\n","model_name = 't5-small'  #@param [\"t5-base\",\"t5-small\",\"t5-large\"] {type:\"string\"}\n","TARGET_LANGUAGE = 'portuguese'  #@param {type:\"string\"}\n","SOURCE_LANGUAGE = 'english' #@param {type:\"string\"}\n","PREFIX = 'translate English to Portuguese: '"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hhma48M02WXc","colab_type":"text"},"source":["# Instalação de pacotes , imports e configurações gerais"]},{"cell_type":"markdown","metadata":{"id":"X_-dr3SD3Kii","colab_type":"text"},"source":["### Pacotes Externos"]},{"cell_type":"code","metadata":{"id":"QYmkRMp-2TzA","colab_type":"code","colab":{}},"source":["! pip install pytorch-lightning==0.7.6 --quiet\n","! pip install transformers --quiet\n","! pip install nvidia-smi --quiet\n","! pip install ftfy --quiet\n","! pip install jsonlines --quiet\n","! pip install sacrebleu --quiet"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9q-wNGh4yOB7","colab_type":"text"},"source":["### Funções auxiliares "]},{"cell_type":"code","metadata":{"id":"-NS1Cif6yBrP","colab_type":"code","colab":{}},"source":["%%capture\n","!wget -nc https://raw.githubusercontent.com/Matheus158257/ms-marco-passage-ranking-dense-vectors-with-doc2query/master/read_ms_marco.py\n","!wget -nc https://raw.githubusercontent.com/Matheus158257/ms-marco-passage-ranking-dense-vectors-with-doc2query/master/read_ms_marco2.py"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BAYGTOsyDutH","colab_type":"text"},"source":["### Paths"]},{"cell_type":"markdown","metadata":{"id":"zVmP7qvND0Dq","colab_type":"text"},"source":["Root"]},{"cell_type":"code","metadata":{"id":"2uK-GSvcDxCs","colab_type":"code","colab":{}},"source":["import os\n","# data_base_dir = '/content/drive/My Drive/Mestrado/PLN/Projeto/Data/Traducao/Natural_Questions' #Matheus\n","data_base_dir = '/content/drive/My Drive/Projeto/Data/Traducao/Natural_Questions'\n","# data_base_dir = '/content/drive/My Drive/Projeto/Data/Traducao/Natural_Questions' #Graziella\n","# check_path = '/content/drive/My Drive/Projeto/Data/Traducao/checkpoints'\n","check_path = '/content/drive/My Drive/Projeto/Data/Traducao'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9oBeoV6D1jA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"error","timestamp":1593032685708,"user_tz":180,"elapsed":1001,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"3318fa4c-a4e1-444e-ee94-001f03834bc3"},"source":["# NO CHUNCK\n","nq_doct_text_path =  data_base_dir + '/nq_doc_text.csv'\n","nq_long_answer_path =  data_base_dir + '/nq_long_answer.csv'\n","nq_short_answers_path =  data_base_dir + '/nq_short_answer.csv'\n","nq_question_path =  data_base_dir + '/nq_question.csv'\n","nq_infos_path =  data_base_dir + '/nq_infos.csv'\n","\n","# # CHUNCK\n","# nq_doct_text_chunk_path =  data_base_dir + '/nq_doc_text_chunk.csv'\n","# nq_long_answer_chunk_path =  data_base_dir + '/nq_long_answer_chunk.csv'\n","# nq_short_answers_chunk_path =  data_base_dir + '/nq_short_answer_chunk.csv'\n","# nq_question_chunk_path =  data_base_dir + '/nq_question_chunk.csv'\n","# nq_infos_chunk_path =  data_base_dir + '/nq_infos_chunk.csv'"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-962d990ae016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# NO CHUNCK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnq_doct_text_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdata_base_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/nq_doc_text.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnq_long_answer_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdata_base_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/nq_long_answer.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnq_short_answers_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdata_base_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/nq_short_answer.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnq_question_path\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdata_base_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/nq_question.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data_base_dir' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"2NhaFts_1Z9p","colab_type":"text"},"source":["### Imports\n"]},{"cell_type":"code","metadata":{"id":"HDSydySz1YZ2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":117},"executionInfo":{"status":"ok","timestamp":1593004179169,"user_tz":180,"elapsed":29341,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"963b0e4e-8379-45da-b59e-10df6d14d8d5"},"source":["#Bibliotecas Padrão\n","import os\n","import random\n","from typing import Dict\n","from typing import List\n","from typing import Tuple\n","import re\n","import gzip\n","import math\n","import jsonlines\n","import pdb\n","import ftfy\n","\n","\n","#Bibliotecas Data Science\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import OrdinalEncoder,LabelEncoder\n","import numpy as np\n","import pandas as pd\n","\n","#Bibliotecas Pytorch\n","import torch\n","from torch.utils.data import Dataset\n","from torch import Tensor\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","\n","#Bibliotecas Lightning\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","#Bibliotecas transfromers\n","from transformers import T5ForConditionalGeneration\n","from transformers import T5Tokenizer\n","\n","#import das funções que vem do github\n","import collections\n","import functools\n","import traceback\n","import sys\n","import os\n","from read_ms_marco2 import load_qrels\n","from read_ms_marco2 import load_queries\n","from read_ms_marco import load_collection\n","from read_ms_marco import load_doc2query\n","from read_ms_marco import load_triple\n","from read_ms_marco2 import load_txts_topk #load_txts_topk(folder,k=1,n=18,encoding=\"cp1252\")\n","\n","# Score Metrics\n","import sacrebleu\n","\n","# Initialize tensorboard\n","print(\"\\nInitialize=ing Tensorboard...\\n\")\n","%load_ext tensorboard\n","\n","# Device\n","if torch.cuda.is_available(): \n","   dev = \"cuda:0\"\n","else: \n","   dev = \"cpu\" \n","print(dev)\n","device = torch.device(dev)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Initialize=ing Tensorboard...\n","\n","The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n","cuda:0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zjdS8RtpVJh2","colab_type":"text"},"source":["### Fix seeds "]},{"cell_type":"code","metadata":{"id":"KvQu-u2-VGvp","colab_type":"code","colab":{}},"source":["seed = 123\n","random.seed(seed)\n","# np.random.seed(seed)\n","torch.random.manual_seed(seed)\n","torch.cuda.manual_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BEN-2TdgAHev","colab_type":"text"},"source":["### Montar o Drive"]},{"cell_type":"code","metadata":{"id":"Y4Sv8Yt3AGo0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1593004179174,"user_tz":180,"elapsed":29209,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"8187ae0f-7b08-4ea2-9dab-3da21e62da60"},"source":["#Mount drive\n","print(\"\\nMounting Drive...\\n\")\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Mounting Drive...\n","\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bVVL_T-czlGc","colab_type":"text"},"source":["Impedir excesso de logs"]},{"cell_type":"code","metadata":{"id":"bRtOKuWQzkWc","colab_type":"code","colab":{}},"source":["import logging\n","logging.getLogger(\"transformers.configuration_utils\").setLevel(logging.WARNING)\n","logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARNING)\n","logging.getLogger(\"lightning\").setLevel(logging.WARNING)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ix3quSjn3BQG","colab_type":"text"},"source":["###Impedir quebra de memória"]},{"cell_type":"code","metadata":{"id":"E2utGlND24OS","colab_type":"code","colab":{}},"source":["# https://docs.fast.ai/troubleshoot.html#memory-leakage-on-exception\n","import functools, traceback\n","def gpu_mem_restore(func):\n","    @functools.wraps(func)\n","    def wrapper(*args, **kwargs):\n","        try:\n","            return func(*args, **kwargs)\n","        except:\n","            type, val, tb = sys.exc_info()\n","            traceback.clear_frames(tb)\n","            raise type(val).with_traceback(tb) from None\n","    return wrapper\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YrAnSTTJ29MY","colab_type":"text"},"source":["###Hardware Data"]},{"cell_type":"code","metadata":{"id":"26_NBrbq27iA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1593004179181,"user_tz":180,"elapsed":29083,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"a3d6df96-1727-4a30-d639-116dd761ca72"},"source":["import nvidia_smi\n","import psutil\n","from multiprocessing import cpu_count\n","nvidia_smi.nvmlInit()\n","handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n","print(\"\\nGetting Hardware Statatus...\\n\")\n","def hardware_stats():\n","    '''\n","    Returns a dict containing some hardware related stats\n","    '''\n","    res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n","    return {\"cpu\": str(psutil.cpu_percent()) + '%',\n","            \"mem\": str(psutil.virtual_memory().percent) + '%',\n","            \"gpu\": str(res.gpu) + '%',\n","            \"gpu_mem\": str(res.memory) + '%'}\n","\n","print(f\"Imports loaded succesfully. Current GPU: {torch.cuda.get_device_name(0)}, number of CPU cores: {cpu_count()}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Getting Hardware Statatus...\n","\n","Imports loaded succesfully. Current GPU: Tesla K80, number of CPU cores: 2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M3FgYAqpwm9B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1593004179184,"user_tz":180,"elapsed":29054,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"8390db84-ee87-4553-ec80-ec46086a2bd3"},"source":["print(f\"Pytorch Lightning Version: {pl.__version__}\")\n","nvidia_smi.nvmlInit()\n","handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n","print(f\"Device name: {nvidia_smi.nvmlDeviceGetName(handle)}\")\n","print(f\"Number of CPU cores: {cpu_count()}\")\n","\n","def gpu_usage():\n","    global handle\n","    return str(nvidia_smi.nvmlDeviceGetUtilizationRates(handle).gpu) + '%'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Pytorch Lightning Version: 0.7.6\n","Device name: b'Tesla K80'\n","Number of CPU cores: 2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h7yaw28Hbmhb","colab_type":"text"},"source":["# Trabalhando o modelo"]},{"cell_type":"code","metadata":{"id":"EaQUQWziboPk","colab_type":"code","colab":{}},"source":["tokenizer = T5Tokenizer.from_pretrained(model_name)\n","model = T5ForConditionalGeneration.from_pretrained(model_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZXMZ3XDdhNJ","colab_type":"code","colab":{}},"source":["extra_tokens = ['À' , 'È' , 'Ì' , 'Ò' , 'Ù' , 'à' , 'è' , 'ì' , 'ò' , 'ù' , 'Á' , 'É' , 'Í' , 'Ó' , 'Ú' , 'á' , 'é' , 'í' , 'ó' , 'ú' , 'Â' , 'Ê' , 'Î' , 'Ô' , 'Û' , 'â' , 'ê' , 'î' , 'ô' , 'û'  , 'Ã' , 'Õ'  , 'ã', 'õ' , 'Ë', 'ä' , 'ë' , 'ï' , 'ö' , 'ü']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6QL7cunFdhy9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1593004182702,"user_tz":180,"elapsed":32428,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"3b44e44e-ab6b-426e-824f-14b7f19850e3"},"source":["tokenizer.add_tokens('não')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"CyAwTio-d__i","colab_type":"code","colab":{}},"source":["# tokenizer.add_tokens('<CHUNK>')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sKTo1AXedo6a","colab_type":"text"},"source":["Alguns dos tokens de acentuação já existem no dataset. Checamos isso fazendo o encoding do token. Se existir, ele retorna um token x. Se não, retorna 2. Se for 2, a gente adiciona para o tokenizador"]},{"cell_type":"code","metadata":{"id":"z0Qkl5pUdryK","colab_type":"code","colab":{}},"source":["added_tokens = []\n","for tok in extra_tokens:\n","    enc = tokenizer.encode(tok)\n","    if 2 in enc:\n","        added_tokens.append(tok)\n","        tokenizer.add_tokens(tok)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zn01CkYhd5HJ","colab_type":"code","colab":{}},"source":["def fix_accent_breaks(text):\n","    \"\"\"\n","    A ideia é fazer a junção de letras com acento de volta para frases na validação.\n","    Isso serve para melhorar o BLEU.\n","    \n","    Args\n","        text: texto que terá acentuação corrigida\n","        \n","    Returns:\n","        Texto completo com acentuação corrigida\n","    \n","    \n","    \n","    \"\"\"\n","    words = text.split(\" \")\n","    out_words = []\n","    merge_pos = [idx for idx, dat in enumerate(words) if dat in added_tokens]\n","    for pos in sorted(merge_pos, reverse=True):\n","        if pos==0:\n","            new_word = words[pos]+words[pos+1]\n","            for i in range(2): words.pop\n","            words.pop(pos+1)\n","            words.pop(pos)        \n","            words.insert(pos, new_word)\n","        elif pos==len(words)-1:\n","            new_word = words[pos-1]+words[pos]\n","            words.pop(pos)\n","            words.pop(pos-1)\n","            words.insert(pos-1, new_word)\n","        else:\n","            new_word = words[pos-1]+words[pos]+words[pos+1]\n","            words.pop(pos+1)\n","            words.pop(pos)\n","            words.pop(pos-1)\n","            words.insert(pos-1, new_word)\n","\n","    return \" \".join(words)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DjUeKsT3ELzL","colab_type":"text"},"source":["# Etapas do paracrawl -> Treino\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"0xx13y8S3WyS","colab_type":"text"},"source":["## Data Prep"]},{"cell_type":"code","metadata":{"id":"LyiluXz2WbZS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1593004186761,"user_tz":180,"elapsed":36400,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"f6b72277-97a4-4016-a4f5-3e3cc09fbd75"},"source":["! wget -nc https://storage.googleapis.com/neuralresearcher_data/unicamp/ia376e_2020s1/paracrawl_enpt_train.tsv.gz\n","! wget -nc https://storage.googleapis.com/neuralresearcher_data/unicamp/ia376e_2020s1/paracrawl_enpt_test.tsv.gz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["File ‘paracrawl_enpt_train.tsv.gz’ already there; not retrieving.\n","\n","File ‘paracrawl_enpt_test.tsv.gz’ already there; not retrieving.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lrf6bAHIWjqm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":488},"executionInfo":{"status":"ok","timestamp":1593004194476,"user_tz":180,"elapsed":44028,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"4c260988-67a5-4fd2-ab67-ef708431c3da"},"source":["def load_text_pairs(path):\n","    text_pairs = []\n","    for line in gzip.open(path, mode='rt'):\n","        text_pairs.append(line.strip().split('\\t'))\n","    return text_pairs\n","\n","ds_train = load_text_pairs('paracrawl_enpt_train.tsv.gz')\n","ds_test = load_text_pairs('paracrawl_enpt_test.tsv.gz')\n","\n","# Embaralhamos o treino para depois fazermos a divisão treino/val.\n","random.shuffle(ds_train)\n","\n","# Truncamos o dataset para 100k pares de treino e 5k pares de validação.\n","ds_val = ds_train[100000:105000]\n","ds_train = ds_train[:100000]\n","\n","for set_name, x in [('treino', ds_train), ('validação',ds_val), ('test', ds_test)]:\n","    print(f'\\n{len(x)} amostras de {set_name}')\n","    print(f'3 primeiras amostras {set_name}:')\n","    for i, (source, target) in enumerate(x[:3]):\n","        print(f'{i}: source: {source}\\n   target: {target}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","100000 amostras de treino\n","3 primeiras amostras treino:\n","0: source: More Croatian words and phrases\n","   target: Mais palavras e frases em croata\n","1: source: Jerseys and pullovers, containing at least 50Â % by weight of wool and weighing 600Â g or more per article 6110 11 10 (PCE)\n","   target: Camisolas e pulôveres, com pelo menos 50 %, em peso, de lã e pesando 600g ou mais por unidade 6110 11 10 (PCE)\n","2: source: Atex Colombia SAS makes available its lead product, 100% natural liquid latex, excellent quality and price. ... Welding manizales caldas Colombia a DuckDuckGo\n","   target: Atex Colômbia SAS torna principal produto está disponível, látex líquido 100% natural, excelente qualidade e preço. ...\n","\n","5000 amostras de validação\n","3 primeiras amostras validação:\n","0: source: «You have hidden these things from the wise and the learned you have revealed them to the childlike»\n","   target: «Escondeste estas coisas aos sábios e entendidos e as revelaste aos pequenos»\n","1: source: Repair of computers, application programming, network installations, web design, graphic design, and also the most. Computer consulting in Santa Lucía\n","   target: Reparação de computadores, programação de aplicações, instalações de rede, web design, design gráfico, e também a.\n","2: source: He was born in Fafe (Braga) and he graduated in Law in Coimbra University.\n","   target: É natural de Fafe (Braga) e Licenciado em Direito pela Universidade de Coimbra.\n","\n","20000 amostras de test\n","3 primeiras amostras test:\n","0: source: In this way, the civil life of a nation matures, making it possible for all citizens to enjoy the fruits of genuine tolerance and mutual respect.\n","   target: Deste modo, a vida civil de uma nação amadurece, fazendo com que todos os cidadãos gozem dos frutos da tolerância genuína e do respeito mútuo.\n","1: source: 1999 XIII. Winnipeg, Canada July 23 to August 8\n","   target: 1999 XIII. Winnipeg, Canadá 23 de julho a 8 de agosto\n","2: source: In the mystery of Christmas, Christ's light shines on the earth, spreading, as it were, in concentric circles.\n","   target: No mistério do Natal, a luz de Cristo irradia-se sobre a terra, difundindo-se como círculos concêntricos.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"peek8f-gbDOS","colab_type":"text"},"source":["## Classe de dataset"]},{"cell_type":"code","metadata":{"id":"rRi8dOr6elow","colab_type":"code","colab":{}},"source":["class ParacrawlDataset(Dataset):\n","    def __init__(self, text_pairs: List[Tuple[str]], tokenizer,\n","                 source_max_length: int = 32, target_max_length: int = 32):\n","        self.tokenizer = tokenizer\n","        self.text_pairs = text_pairs\n","        self.source_max_length = source_max_length\n","        self.target_max_length = target_max_length\n","        \n","    def __len__(self):\n","        return len(self.text_pairs)\n","    \n","    def __getitem__(self, idx):\n","        source, target = self.text_pairs[idx]\n","        source_modified = 'translate English to Portuguese: '+ source + self.tokenizer.eos_token\n","        target_modified = target + self.tokenizer.eos_token\n","        \n","        source_tok = tokenizer.batch_encode_plus([source_modified], add_special_tokens=True,\n","                                                max_length=self.source_max_length, pad_to_max_length = True, \n","                                                return_tensors='pt')\n","        target_tok = tokenizer.batch_encode_plus([target_modified], add_special_tokens=True,\n","                                                max_length=self.target_max_length, pad_to_max_length = True, \n","                                                return_tensors='pt')\n","        \n","        return (source_tok['input_ids'][0], source_tok['attention_mask'][0], target_tok['input_ids'][0], \n","                target_tok['attention_mask'][0], source, target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ab172wkglRYL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"status":"ok","timestamp":1593004194479,"user_tz":180,"elapsed":43990,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"51af733f-d1f6-4cc0-97e1-56891d3b58b0"},"source":["text_pairs = [('Dear friends, the history of this nation includes many examples of the Church’s commitment in this regard.',\n","               'Queridos amigos, a história desta Nação oferece numerosos exemplos do compromisso da Igreja a este propósito.')]\n","dataset_debug = ParacrawlDataset(\n","    text_pairs=text_pairs,\n","    tokenizer=tokenizer,\n","    source_max_length=50,\n","    target_max_length=50)\n","\n","dataloader_debug = DataLoader(dataset_debug, batch_size=10, shuffle=True, \n","                              num_workers=0)\n","\n","source_token_ids, source_mask, target_token_ids, target_mask, _, _ = next(iter(dataloader_debug))\n","print('source_tokens:\\n', tokenizer.tokenize(text_pairs[0][0]))\n","print('source_token_ids:\\n', source_token_ids)\n","print('source_mask:\\n', source_mask)\n","print('target_tokens:\\n', tokenizer.tokenize(text_pairs[0][1]))\n","print('target_token_ids:\\n', target_token_ids)\n","print('target_mask:\\n', target_mask)\n","\n","print('source_token_ids.shape:', source_token_ids.shape)\n","print('source_mask.shape:', source_mask.shape)\n","print('target_token_ids.shape:', target_token_ids.shape)\n","print('target_mask.shape:', target_mask.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["source_tokens:\n"," ['▁Dear', '▁friends', ',', '▁the', '▁history', '▁of', '▁this', '▁nation', '▁includes', '▁many', '▁examples', '▁of', '▁the', '▁Church', '’', 's', '▁commitment', '▁in', '▁this', '▁regard', '.']\n","source_token_ids:\n"," tensor([[13959,  1566,    12, 21076,    10, 19451,   803,     6,     8,   892,\n","            13,    48,  2982,   963,   186,  4062,    13,     8,  2345,    22,\n","             7,  3148,    16,    48,  3553,     5,     1,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n","source_mask:\n"," tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0]])\n","target_tokens:\n"," ['▁Qu', 'er', 'idos', '▁', 'ami', 'go', 's', ',', '▁', 'a', '▁his', 't', 'ó', 'r', 'i', 'a', '▁de', 'sta', '▁Na', 'ç', 'ã', '▁', 'o', '▁of', 'er', 'e', 'ce', '▁numero', 's', 'o', 's', '▁', 'exe', 'mp', 'los', '▁do', '▁compromis', 's', 'o', '▁da', '▁I', 'gre', 'ja', '▁', 'a', '▁este', '▁prop', 'ó', 's', 'i', 'to', '.']\n","target_token_ids:\n"," tensor([[ 2415,    49, 28594,     3,  3690,   839,     7,     6,     3,     9,\n","           112,    17,  4922,    52,    23,     9,    20,  2427,  1823,  8970,\n","         32120,     3,    32,    13,    49,    15,   565, 30057,     7,    32,\n","             7,     3,  6667,  1167,  2298,   103, 29296,     7,    32,   836,\n","            27,  3584,  1191,     3,     9,   249,  6377,  4922,     7,    23]])\n","target_mask:\n"," tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1]])\n","source_token_ids.shape: torch.Size([1, 50])\n","source_mask.shape: torch.Size([1, 50])\n","target_token_ids.shape: torch.Size([1, 50])\n","target_mask.shape: torch.Size([1, 50])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lfOclX91ypPD","colab_type":"text"},"source":["# Etapa NaturalQuestions -> Inferência"]},{"cell_type":"markdown","metadata":{"id":"2ztCXqrm1svJ","colab_type":"text"},"source":["## Data prep"]},{"cell_type":"code","metadata":{"id":"GG_EizM4EC9u","colab_type":"code","colab":{}},"source":["doct_text_df = pd.read_csv(nq_doct_text_path)\n","long_answer_df = pd.read_csv(nq_long_answer_path)\n","short_answers_df = pd.read_csv(nq_short_answers_path)\n","question_df = pd.read_csv(nq_question_path)\n","infos_df = pd.read_csv(nq_infos_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDxZ6ouYqBLm","colab_type":"code","colab":{}},"source":["# doct_text_df = pd.read_csv(nq_doct_text_chunck_path)\n","# long_answer_df = pd.read_csv(nq_long_answer_chunck_path)\n","# short_answers_df = pd.read_csv(nq_short_answers_chunck_path)\n","# question_df = pd.read_csv(nq_question_chunck_path)\n","# infos_df = pd.read_csv(nq_infos_chunck_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZcJLaQvtlYA7","colab_type":"code","colab":{}},"source":["#doct_text_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVCHKKC0laG7","colab_type":"code","colab":{}},"source":["#long_answer_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aSBZN1P2laMa","colab_type":"code","colab":{}},"source":["#short_answers_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLNNLUBZlaUJ","colab_type":"code","colab":{}},"source":["#question_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7WQ-nxxulaQz","colab_type":"code","colab":{}},"source":["#infos_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R9uaZEl41xr6","colab_type":"text"},"source":["## Classe Data set"]},{"cell_type":"code","metadata":{"id":"TFPfmhnt2cKT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1593004195339,"user_tz":180,"elapsed":44794,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"3a61294a-63fc-40cc-ffb3-de09339431ff"},"source":["phrase = 'Eu não gostaria de fazer parte desta pandemia'\n","encoder = tokenizer.encode_plus(phrase,\n","                      max_length =15,\n","                      pad_to_max_length=True,\n","                      add_special_tokens = True)\n","print('TOKENIZAÇÃO: ',tokenizer.tokenize(phrase))\n","print('ENCODER: ',encoder)\n","print('DECODIFICANDO: ', tokenizer.decode(encoder['input_ids']))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TOKENIZAÇÃO:  ['▁Eu', 'não', '▁go', 's', 'tari', 'a', '▁de', '▁', 'f', 'a', 'zer', '▁parte', '▁de', 'sta', '▁pan', 'd', 'emia']\n","ENCODER:  {'input_ids': [4491, 32100, 281, 7, 5310, 9, 20, 3, 89, 9, 2558, 2359, 20, 2427, 2131], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n","DECODIFICANDO:  Eu não gostaria de fazer parte desta pan\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l2usvNaqvzKD","colab_type":"code","colab":{}},"source":["doct_text_df_debug =doct_text_df[:10]\n","long_answer_df_debug = long_answer_df[:10]\n","short_answers_df_debug = short_answers_df[:10]\n","question_df_debug = question_df[:10]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OLE7Uj_f5ca4","colab_type":"code","colab":{}},"source":["class QuestionDataset(Dataset):\n","    def __init__(self, question,tokenizer,max_length,training_step=False):\n","        self.question = question\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.question)\n","\n","    def __getitem__(self, idx):\n","        data = self.question.iloc[idx]\n","        id_example = data['ID']\n","        question = data['QUESTION']\n","        q_tok, q_mask, q_type = self.encode_plus(ftfy.fix_text(question))\n","\n","        return  q_tok, q_mask, q_type, id_example\n","\n","    def encode_plus(self, text):\n","        tokens = self.tokenizer.encode_plus(text=text, max_length=self.max_length,\n","                                       pad_to_max_length=True, add_special_tokens = True)\n","        tok =  torch.tensor(tokens[\"input_ids\"]).type(torch.long)\n","        mask = torch.tensor(tokens['attention_mask']).type(torch.long)\n","        tok_type = torch.tensor(tokens['token_type_ids']).type(torch.long)\n","        return tok,mask,tok_type"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CStGdYJIhyiw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":167},"executionInfo":{"status":"ok","timestamp":1593004195942,"user_tz":180,"elapsed":45346,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"db7748ed-733d-48b5-f5b8-91ca1badeefc"},"source":["question_debug = QuestionDataset(\n","    question = question_df_debug,\n","    tokenizer=tokenizer,\n","    max_length=20)\n","\n","dataloader_debug = DataLoader(question_debug, batch_size=2, shuffle=True,num_workers=cpu_count())\n","\n","q_tok, q_mask, q_type, id_example = next(iter(dataloader_debug))\n","print(id_example)\n","print(q_tok)\n","print(q_mask)\n","print(q_type)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([5328212470870865242, 5611750702541347162])\n","tensor([[  149,     3,    23,     5,  3493,    39,  2039,   113,    19,     8,\n","          2039,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  113,   410,     8,  2249,    13,     8, 31412,    16,  2515,  3481,\n","            63,     8,  2983,   348,     0,     0,     0,     0,     0,     0]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])\n","tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yAkIe41NgBmk","colab_type":"code","colab":{}},"source":["tokenizer.decode(q_tok)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9BDS1NY3suP1","colab_type":"code","colab":{}},"source":["class LongAnswerDataset(Dataset):\n","    def __init__(self, long_answer,tokenizer,max_length,training_step=False):\n","        self.long_answer = long_answer\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return 5\n","\n","    def __getitem__(self, idx):\n","        data = self.long_answer.iloc[idx]\n","        id_example = data['ID']\n","        long_answer = data['LONG_ANSWER']\n","        start = data['START_LA']\n","        end = data['END_LA']\n","        la_tok, la_mask, la_type = self.encode_plus(ftfy.fix_text(long_answer))\n","\n","        return  la_tok, la_mask, la_type,id_example,start,end\n","\n","    def encode_plus(self, text):\n","        tokens = self.tokenizer.encode_plus(text=text, max_length=self.max_length,\n","                                       pad_to_max_length=True, add_special_tokens = True)\n","        tok =  torch.tensor(tokens[\"input_ids\"]).type(torch.long)\n","        mask = torch.tensor(tokens['attention_mask']).type(torch.long)\n","        tok_type = torch.tensor(tokens['token_type_ids']).type(torch.long)\n","        return tok,mask,tok_type"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sUXfx8L2NxLM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"ok","timestamp":1593004195946,"user_tz":180,"elapsed":45281,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"42448038-6e8a-4f16-b60f-6aaafc164d7a"},"source":["la_debug = LongAnswerDataset(\n","    long_answer = long_answer_df_debug,\n","    tokenizer=tokenizer,\n","    max_length=20)\n","\n","dataloader_debug = DataLoader(la_debug, batch_size=2, shuffle=True,num_workers=cpu_count())\n","\n","la_tok, la_mask, la_type,id_example,start,end= next(iter(dataloader_debug))\n","\n","print(id_example)\n","print(start)\n","print(end)\n","print(la_tok)\n","print(la_mask)\n","print(la_type)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([5655493461695504401, 5328212470870865242])\n","tensor([1718,  132])\n","tensor([1783,  228])\n","tensor([[   86,    48,   686,    13,  3662,     3,     6,     3,     9,   349,\n","            24,  2746,    12,  1299,     3,     9,  7288,    12,    70,   722],\n","        [29464,  7040,   106, 10361,     3,     6,   394,   801,    38,     3,\n","             2,    37,  8007,     3,    31,    31,     3,     6,    19,     8]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Kgfwa0oitvEF","colab_type":"code","colab":{}},"source":["class ShortAnswerDataset(Dataset):\n","    def __init__(self, short_answer,tokenizer,max_length,training_step=False):\n","        self.short_answer = short_answer\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.short_answer)\n","\n","    def __getitem__(self, idx):\n","        data = self.short_answer.iloc[idx]\n","        id_example = data['ID']\n","        short_answer = data['SHORT_ANSWER']\n","        start = data['START_SA']\n","        end = data['END_SA']\n","        sa_tok, sa_mask, sa_type = self.encode_plus(ftfy.fix_text(short_answer))\n","        return  sa_tok, sa_mask, sa_type,id_example,start,end\n","\n","    def encode_plus(self, text):\n","        tokens = self.tokenizer.encode_plus(text=text, max_length=self.max_length,\n","                                       pad_to_max_length=True, add_special_tokens = True)\n","        tok =  torch.tensor(tokens[\"input_ids\"]).type(torch.long)\n","        mask = torch.tensor(tokens['attention_mask']).type(torch.long)\n","        tok_type = torch.tensor(tokens['token_type_ids']).type(torch.long)\n","        return tok,mask,tok_type"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15eMZqJrN-gh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"ok","timestamp":1593004195948,"user_tz":180,"elapsed":45221,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"1b09325c-101d-4d87-f872-c0a3fa1ec825"},"source":["sa_debug = ShortAnswerDataset(\n","    short_answer = short_answers_df_debug,\n","    tokenizer=tokenizer,\n","    max_length=20)\n","\n","dataloader_debug = DataLoader(sa_debug, batch_size=2, shuffle=True,num_workers=cpu_count())\n","\n","sa_tok, sa_mask, sa_type,id_example,start,end= next(iter(dataloader_debug))\n","print(id_example)\n","print(start)\n","print(end)\n","print(sa_tok)\n","print(sa_mask)\n","print(sa_type)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([-1446769669686008214,  -341902602485554777])\n","tensor([3968,  103])\n","tensor([3993,  107])\n","tensor([[   46,  3165,  6681,  2535,   113,    19,    44,   709,  1401,   203,\n","            13,  1246,    42,  2749,    11,    16,     8, 10837,  3143,    13],\n","        [ 8208,    32, 17457,   325,   354,     2,  2975,   157,    13, 30629,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5zyZdNuAtbo5","colab_type":"code","colab":{}},"source":["class DocTextDataset(Dataset):\n","    def __init__(self, doc_text,tokenizer,max_length,training_step=False):\n","        self.doc_text = doc_text\n","        self.max_length = max_length\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.doc_text)\n","\n","    def __getitem__(self, idx):\n","        data = self.doc_text.iloc[idx]\n","        id_example = data['ID']\n","        doc_text = data['DOC_TEXT']\n","        dt_tok, dt_mask, dt_type = self.encode_plus(ftfy.fix_text(doc_text))\n","\n","        return  dt_tok, dt_mask, dt_type,id_example\n","\n","    def encode_plus(self, text):\n","        tokens = self.tokenizer.encode_plus(text=text, max_length=self.max_length,\n","                                       pad_to_max_length=True, add_special_tokens = True)\n","        tok =  torch.tensor(tokens[\"input_ids\"]).type(torch.long)\n","        mask = torch.tensor(tokens['attention_mask']).type(torch.long)\n","        tok_type = torch.tensor(tokens['token_type_ids']).type(torch.long)\n","        return tok,mask,tok_type"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubzIWqEoONkR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":167},"executionInfo":{"status":"ok","timestamp":1593004195950,"user_tz":180,"elapsed":45161,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"1aee861e-ad3b-4dd5-a185-66136648a28d"},"source":["doc_debug = DocTextDataset(\n","    doc_text = doct_text_df_debug,\n","    tokenizer=tokenizer,\n","    max_length=20)\n","\n","dataloader_debug = DataLoader(doc_debug, batch_size=2, shuffle=True,num_workers=cpu_count())\n","\n","dt_tok, dt_mask, dt_type,id_example= next(iter(dataloader_debug))\n","print(id_example)\n","print(dt_tok)\n","print(dt_mask)\n","print(dt_type)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([5655493461695504401, 5655493461695504401])\n","tensor([[  597, 15551,  1037,   164,    36, 15514,    11,  3641,     3,     5,\n","            41,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [ 4001,   149,    11,   116,    12,  2036,   175,  3847,  4175,     3,\n","            61,   100,  1108,   523,  1151,     3, 13903,     7,    21, 17549]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n","tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ervX76G65NNK","colab_type":"text"},"source":["# Hyperparâmetros"]},{"cell_type":"code","metadata":{"id":"3DdFSPOeT8nj","colab_type":"code","colab":{}},"source":["classification_specific = False #@param {type:\"boolean\"}\n","batch_size =  32#@param {type:\"integer\"}\n","max_epochs = 2 #@param {type:\"integer\"}\n","accumulate_grad_batches = 8  #@param {type:\"integer\"}\n","source_max_length = 64  #@param {type:\"integer\"}\n","target_max_length = 128  #@param {type:\"integer\"}\n","max_lenght_NQ = 500  #@param {type:\"integer\"}\n","learning_rate = 5e-3  #@param {type:\"number\"}\n","context_size = 20"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"74lzNy0IuIfU","colab_type":"code","colab":{}},"source":["hyperparms = {'model_name':model_name,'tokenizer':tokenizer,'learning_rate':learning_rate,'batch_size':batch_size,'source_max_length':source_max_length,'target_max_length':target_max_length,'context_size':context_size,'max_lenght_NQ':max_lenght_NQ} "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nA5W-PYWm_d4","colab_type":"text"},"source":["## Criando o BERT com Pytorch Lightning"]},{"cell_type":"code","metadata":{"id":"F8Mpn7rXm7Tj","colab_type":"code","colab":{}},"source":["class T5Finetuner(pl.LightningModule):\n","\n","    def __init__(self, \n","                 all_data, \n","                 hyperparms,\n","                 criterion = torch.nn.CrossEntropyLoss(),\n","                 overfit=False):\n","      \n","\n","        super(T5Finetuner, self).__init__()\n","\n","        #---------- Hyperparametros\n","        self.model_name = hyperparms['model_name']\n","        self.tokenizer = hyperparms['tokenizer']\n","        self.learning_rate = hyperparms['learning_rate']\n","        self.batch_size = hyperparms['batch_size']\n","        self.target_max_length = hyperparms['target_max_length']\n","        self.source_max_length = hyperparms['source_max_length']\n","        self.max_lenght_NQ = hyperparms['max_lenght_NQ']\n","        self.overfit = overfit\n","        self.training = False\n","\n","      \n","        self.model = T5ForConditionalGeneration.from_pretrained(self.model_name)\n","\n","       #---------- Carregamento datasets (Para eu poder variar self.max_length)\n","        if overfit:\n","          self.train_dataset = ParacrawlDataset(all_data[0], tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n","          self.train_dataset = ParacrawlDataset(all_data[0], tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n","          self.train_dataset = ParacrawlDataset(all_data[0], tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)          \n","          # self.valid_dataset = ParacrawlDataset(all_data[0], tokenizer=self.tokenizer, source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n","          # self.test_dataset =   ParacrawlDataset(all_data[0], tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n","        else:\n","          self.train_dataset = ParacrawlDataset(all_data[0], tokenizer=self.tokenizer, source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n","          self.valid_dataset = ParacrawlDataset(all_data[1], tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n","          self.test_dataset = ParacrawlDataset(all_data[2], tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n","\n","          #self.valid_dataset = QuestionDataset(all_data[1], tokenizer=self.tokenizer, max_lenght_NQ =  self.max_lenght_NQ)\n","          #self.test_dataset = QuestionDataset(all_data[2],  tokenizer=self.tokenizer, max_lenght_NQ =  self.max_lenght_NQ)\n","        \n","        \n","        #---------- Loss Function\n","        self.loss_funtion = criterion\n","\n","    \n","\n","    def translate(self, source_token_ids, source_mask):\n","      predicted_token_ids = self.model.generate(input_ids=source_token_ids, max_length=self.target_max_length)\n","      return predicted_token_ids\n","\n","    def forward(self, source_token_ids, source_mask, target_token_ids=None,target_mask=None, training=False):\n","\n","      if training:\n","          #peguei a ideia da documentação oficial. Setar -100 pro pad faz ele ser ignorado no crossentropy.\n","          target_token_ids[target_token_ids == self.tokenizer.pad_token_id] = -100 \n","          \n","          loss = self.model(source_token_ids, attention_mask = source_mask, lm_labels = target_token_ids)\n","          return loss[0]\n","\n","      else:\n","          #gerador de tokens de saída - GREEDY\n","          predicted_token_ids = self.model.generate(input_ids=source_token_ids, max_length=self.target_max_length)\n","          return predicted_token_ids\n","\n","\n","    def training_step(self, batch, batch_nb):\n","        # batch\n","        source_token_ids, source_mask, target_token_ids, target_mask, _, _ = batch\n","         \n","        # fwd\n","        loss = self.forward(source_token_ids, source_mask, target_token_ids, target_mask, training=True)\n","\n","        # logs\n","        tensorboard_logs = {'train_loss': loss}\n","        progress_bar = {'gpu_usage': gpu_usage()}\n","        return {'loss': loss, 'log': tensorboard_logs,\n","                'progress_bar': progress_bar}\n","\n","\n","    def validation_step(self, batch, batch_nb):\n","        source_token_ids, source_mask, target_token_ids, target_mask, source, refs = batch\n","        predict = self(source_token_ids, source_mask).permute(0,1)\n","        sys = [fix_accent_breaks(self.tokenizer.decode(tokens)) for tokens in predict]\n","        avg_bleu = sacrebleu.corpus_bleu(sys, [refs]).score\n","        progress_bar = {'gpu_usage': gpu_usage()}\n","        return {'val_bleu': avg_bleu, 'progress_bar': progress_bar}\n","\n","\n","    def test_step(self, batch, batch_nb):\n","        source_token_ids, source_mask, target_token_ids, target_mask, source, refs = batch\n","        predict = self(source_token_ids, source_mask).permute(0,1)\n","        sys = [fix_accent_breaks(self.tokenizer.decode(tokens)) for tokens in predict]\n","        \n","        avg_bleu = sacrebleu.corpus_bleu(sys, [refs]).score\n","        \n","        progress_bar = {'gpu_usage': gpu_usage()}\n","        return {'test_bleu': avg_bleu, 'progress_bar': progress_bar}\n","\n","    def validation_epoch_end(self, outputs):\n","        avg_bleu = sum([x['val_bleu'] for x in outputs]) / len(outputs)\n","        print(\"Avg Bleu val\", avg_bleu)\n","        tensorboard_logs = {'avg_val_bleu': avg_bleu}\n","        \n","        return {'avg_val_bleu': avg_bleu, 'progress_bar': tensorboard_logs}\n","\n","\n","    def test_epoch_end(self, outputs):\n","        avg_bleu = sum([x['test_bleu'] for x in outputs]) / len(outputs)\n","\n","        tensorboard_logs = {'avg_test_bleu': avg_bleu}\n","\n","    def configure_optimizers(self):\n","        return torch.optim.AdamW(\n","            [p for p in self.parameters() if p.requires_grad],\n","            lr=self.learning_rate, eps=1e-08)\n","    \n","    @gpu_mem_restore\n","    def train_dataloader(self):\n","        shuffle = False if self.overfit else True\n","        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=shuffle,num_workers=cpu_count())\n","    \n","    @gpu_mem_restore\n","    def val_dataloader(self):\n","        return DataLoader(self.valid_dataset, batch_size=self.batch_size, shuffle=False,num_workers=cpu_count())\n","    \n","    @gpu_mem_restore\n","    def test_dataloader(self):\n","        return DataLoader(self.test_dataset, batch_size=self.batch_size,shuffle=False, num_workers=cpu_count())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cgnp3rUGxYVp","colab_type":"text"},"source":["# Etapas de Treino e Avaliação"]},{"cell_type":"markdown","metadata":{"id":"Av5AoX0DzVeO","colab_type":"text"},"source":["### Testando rapidamente o modelo em treino, validação e teste com um batch"]},{"cell_type":"markdown","metadata":{"id":"kw2tQjdf15DH","colab_type":"text"},"source":["Recuperando o número de parâmetros"]},{"cell_type":"code","metadata":{"id":"t4mYJq5RyLe2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1593004199145,"user_tz":180,"elapsed":48277,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"18c8e0a6-1c9f-4346-d486-307353236a57"},"source":["all_data = [ds_train,ds_val,ds_test]\n","model = T5Finetuner(all_data,hyperparms) \n","num_params = sum([torch.tensor(x.size()).prod() for x in model.parameters() if x.requires_grad]) # trainable parameters\n","print(num_params)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(60506880)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tLvj4M0vyFj5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":202,"referenced_widgets":["60d48ababbdb4038aca3bff46b036354","9d53a42334e74a6e834ce3a368c465db","b5e672767cc545d9a2d6ffab82baa80a","44356847063d45efb3398613698d2dc5","b7884a11c6cc4f71a3f864324f8c2011","88967357168f41ae972bfb5dd1e1ae06","88606b74e3da433e8b75de83438a2538","6489f51569ad4f49838c89ccfd9bfde3","c25956b7d7114448b26f9fe9636c6416","90371c0ef86f4cf2995cec230fef22f4","6286f2bcfd654f1790948d210a8f38e8","21eb9d74d6ef47cab4e4924c30c612a5","abb2c53ba7124b37b2f221c0cfbfb2fb","90b23e6a949d4ca7996bc22f22b69080","650ac27941b24202b5a9d7f4d0f4a8df","8819c1b8ff9c492aba52f0ee5a03e69d"]},"executionInfo":{"status":"ok","timestamp":1593004217142,"user_tz":180,"elapsed":66218,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"f87d09dd-1ac5-44bc-a3d6-ddeaa6935ef1"},"source":["trainer = pl.Trainer(gpus=1, \n","                     checkpoint_callback=False,  # Disable checkpoint saving.\n","                     fast_dev_run=True)\n","trainer.fit(model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["No environment variable for node rank defined. Set as 0.\n","/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n","  warnings.warn(*args, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60d48ababbdb4038aca3bff46b036354","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c25956b7d7114448b26f9fe9636c6416","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Avg Bleu val 0.7478088493046045\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"6CRjtOq1haS9","colab_type":"code","colab":{}},"source":["del model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UF_bj2Vs4EjA","colab_type":"code","colab":{}},"source":["check_path = '/content/drive/My Drive/Projeto/Data/Traducao'\n","checkpoint_path = check_path + '/Checkpoints_V2/epoch=15.ckpt'\n","print(checkpoint_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"64-8N8LMz4B5","colab_type":"text"},"source":["### Treinamento e Validação no dataset todo"]},{"cell_type":"code","metadata":{"id":"rM4qpdjw0r5i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":268,"referenced_widgets":["171c12fbf43a474ebaaebd765ba89737","cffdf5d406e8449899c50a00742446f0","8908dc493cb6476ab38f1290e650d45b","c1f99fc5893c4698906421c9f6eae268","6437b39e3e8f471393480309381bf975","05b4d9d74bfc47389b3b801f89e6923b","d3c8fd8bb1ac4ca4b940115aabc84ac1","bc1b05f0ad154d89b33396f2a03df164","eec4419ddcc449d791aa84f6562d2baf","481d3cdd37144956b082a29148db9383","6b39770b9f154effb9b31498363bef03","89a6b3a820614ad897d6184f52d304da","91ea95332b7d4db1a268119243fc2f5d","5d6daad420df4a1f8843850507155de2","126891e4ad494cdb8717cafc6c1fdb26","9977b918bb1e4554b7990d964d88a2bb"]},"executionInfo":{"status":"ok","timestamp":1593004343555,"user_tz":180,"elapsed":192576,"user":{"displayName":"Graziella Cardoso Bonadia","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjgXZP-gUVHaQnoUcYNnE-VWuCpoKNPdWW80BJl=s64","userId":"00967507227688148983"}},"outputId":"b83cf1d1-6dde-4f17-a297-3d16025e6ebe"},"source":["# checkpoint_path = check_path + '/epoch=0.ckpt'\n","\n","checkpoint_path = check_path + '/Checkpoints_V2/epoch=15.ckpt'\n","check_path = '/content/drive/My Drive/Projeto/Data/Traducao'\n","checkpoint_dir = os.path.dirname(os.path.abspath(checkpoint_path))\n","print(f'Files in {checkpoint_dir}: {os.listdir(checkpoint_dir)}')\n","print(f'Saving checkpoints to {checkpoint_dir}')\n","checkpoint_callback = ModelCheckpoint(filepath=checkpoint_dir,\n","                                      save_top_k=-1,\n","                                      monitor=\"val_acc\",\n","                                      mode=\"max\")  # Keeps all checkpoints.\n","\n","\n","max_epochs = 14\n","\n","checkpoint_path = '/content/drive/My Drive/Alexandre_aula_10/epoch=13.ckpt'\n","checkpoint_dir = os.path.dirname(os.path.abspath(checkpoint_path))\n","print(f'Files in {checkpoint_dir}: {os.listdir(checkpoint_dir)}')\n","print(f'Saving checkpoints to {checkpoint_dir}')\n","checkpoint_callback = ModelCheckpoint(filepath=checkpoint_dir,\n","                                      save_top_k=-1)  # Keeps all checkpoints.\n","\n","resume_from_checkpoint = None\n","if os.path.exists(checkpoint_path):\n","    print(f'Restoring checkpoint: {checkpoint_path}')\n","    resume_from_checkpoint = checkpoint_path\n","\n","\n","all_data = [ds_train,ds_val,ds_test]\n","trainer = pl.Trainer(gpus=1,\n","                     max_epochs=15,\n","                     check_val_every_n_epoch=1,\n","                     profiler=True,\n","                     checkpoint_callback=checkpoint_callback,\n","                     accumulate_grad_batches=accumulate_grad_batches,\n","                     progress_bar_refresh_rate=50,\n","                     resume_from_checkpoint=resume_from_checkpoint)\n","\n","model = T5Finetuner(all_data,hyperparms) \n","\n","trainer.fit(model)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["No environment variable for node rank defined. Set as 0.\n"],"name":"stderr"},{"output_type":"stream","text":["Files in /content/drive/My Drive/Projeto/Data/Traducao/Checkpoints_V2: ['epoch=0.ckpt', 'epoch=0_v0.ckpt', 'epoch=1.ckpt', 'epoch=2.ckpt', 'epoch=3.ckpt', 'epoch=4.ckpt', 'epoch=5.ckpt', 'epoch=6.ckpt', 'epoch=7.ckpt', 'epoch=8.ckpt', 'epoch=9.ckpt', 'epoch=10.ckpt', 'epoch=11.ckpt', 'epoch=12.ckpt', 'epoch=13.ckpt', 'epoch=14.ckpt']\n","Saving checkpoints to /content/drive/My Drive/Projeto/Data/Traducao/Checkpoints_V2\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"171c12fbf43a474ebaaebd765ba89737","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Avg Bleu val 6.0780716540512225\n","\r"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n","  warnings.warn(*args, **kwargs)\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eec4419ddcc449d791aa84f6562d2baf","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"jlk3ThjaaJqs","colab_type":"text"},"source":["## Colocando no formato do MS MARCO"]},{"cell_type":"markdown","metadata":{"id":"B1Dx58CdaWj7","colab_type":"text"},"source":["### Document"]},{"cell_type":"code","metadata":{"id":"fEr8ayy7ep2J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"error","timestamp":1593038260388,"user_tz":180,"elapsed":1013,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"4d9f62a3-7c91-469d-b712-2b6929fdc9ab"},"source":["# checkpoint_path = check_path + '/epoch=14.ckpt'\n","# model = T5Finetuner.load_from_checkpoint(checkpoint_path = checkpoint_path,\n","#                                          all_data = all_data,\n","#                                          hyperparms=hyperparms).to(device)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-41d3dae6441c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/epoch=14.ckpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model = T5Finetuner.load_from_checkpoint(checkpoint_path = checkpoint_path,\n\u001b[1;32m      3\u001b[0m                                          \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                          hyperparms=hyperparms).to(device)\n","\u001b[0;31mNameError\u001b[0m: name 'check_path' is not defined"]}]},{"cell_type":"code","metadata":{"id":"iVcCNvsbayQ8","colab_type":"code","colab":{}},"source":["doc_text_dataset = DocTextDataset(\n","    doc_text = doct_text_df,\n","    tokenizer=tokenizer,\n","    max_length=max_lenght_NQ)\n","\n","doc_text_dataloader = DataLoader(doc_text_dataset, batch_size=batch_size,num_workers=cpu_count())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uap29Lvxalri","colab_type":"code","colab":{}},"source":["ids = []\n","doc_text_portuguese = []\n","\n","for batch in doc_text_dataloader:\n","    #ids\n","    ids.extend(batch[3].detach().cpu().tolist())    \n","    #doc_text\n","    out = model(batch[0].to(device), batch[1].to(device))\n","    portuguese_translations = [fix_accent_breaks(tokenizer.decode(tokens)) for tokens in out]\n","    doc_text_portuguese.extend(portuguese_translations)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yZfnQQDoeZnS","colab_type":"code","colab":{}},"source":["doct_text_df_portuguese = pd.DataFrame({'ID':ids, 'DOC_TEXT': doc_text_portuguese})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1EWw0qKeqdO","colab_type":"code","colab":{}},"source":["doct_text_df_portuguese.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ByF6f974euOs","colab_type":"code","colab":{}},"source":["compression_opts = dict(method='zip', archive_name='doct_text_df_portuguese.csv') \n","doct_text_df_portuguese.to_csv('doct_text_df_portuguese.zip', index=False,compression=compression_opts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SfjXD4L6aPjb","colab_type":"text"},"source":["### Question"]},{"cell_type":"code","metadata":{"id":"NzoXW2dXoFYU","colab_type":"code","colab":{}},"source":["question_dataset = QuestionDataset(\n","    question = question_df,\n","    tokenizer=tokenizer,\n","    max_length=max_lenght_NQ)\n","\n","question_dataloader = DataLoader(question_dataset, batch_size=batch_size,num_workers=cpu_count())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLqnFcCDt6wW","colab_type":"code","colab":{}},"source":["ids = []\n","question_portuguese = []\n","\n","\n","for batch in question_dataloader:\n","    #ids\n","    ids.extend(batch[3].detach().cpu().tolist())    \n","    #question\n","    out = model(batch[0].to(device), batch[1].to(device))\n","    portuguese_translations = [fix_accent_breaks(tokenizer.decode(tokens)) for tokens in out]\n","    question_portuguese.extend(portuguese_translations)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnZarYPKuZYY","colab_type":"code","colab":{}},"source":["question_df_portuguese = pd.DataFrame({'ID': ids, 'QUESTION': question_portuguese})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uRZynAih4_i8","colab_type":"code","colab":{}},"source":["question_df_portuguese.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CxdzI0dHzkbE","colab_type":"code","colab":{}},"source":["compression_opts = dict(method='zip', archive_name='question_df_portuguese.csv') \n","question_df_portuguese.to_csv('question_df_portuguese.zip', index=False,compression=compression_opts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LAYDFrO6aSU3","colab_type":"text"},"source":["### Long Answer"]},{"cell_type":"code","metadata":{"id":"-g3ldy7DxZqi","colab_type":"code","colab":{}},"source":["long_answer_dataset = LongAnswerDataset(\n","    long_answer = long_answer_df,\n","    tokenizer=tokenizer,\n","    max_length=max_lenght_NQ)\n","\n","long_answer_dataloader = DataLoader(long_answer_dataset, batch_size=batch_size,num_workers=cpu_count())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyqGaKE9xkkK","colab_type":"code","colab":{}},"source":["ids = []\n","long_answer_portuguese = []\n","start_token = []\n","end_token = []\n","\n","for batch in long_answer_dataloader:\n","    #ids\n","    ids.extend(batch[3].detach().cpu().tolist()) \n","    # Start token\n","    start_token.extend(batch[4].detach().cpu().tolist()) \n","    # End token\n","    end_token.extend(batch[5].detach().cpu().tolist()) \n","    #question\n","    out = model(batch[0].to(device), batch[1].to(device))\n","    portuguese_translations = [fix_accent_breaks(tokenizer.decode(tokens)) for tokens in out]\n","    long_answer_portuguese.extend(portuguese_translations)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h3u7k1BM0BbQ","colab_type":"code","colab":{}},"source":["long_answer_df_portuguese = pd.DataFrame({'ID': ids, 'LONG_ANSWER': long_answer_portuguese, 'START_LA': start_token,'END_LA':end_token})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SzFtwE4X5EBZ","colab_type":"code","colab":{}},"source":["long_answer_df_portuguese.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SUvgx16j0Cy8","colab_type":"code","colab":{}},"source":["compression_opts = dict(method='zip', archive_name='long_answer_df_portuguese.csv') \n","long_answer_df_portuguese.to_csv('long_answer_df_portuguese.zip', index=False,compression=compression_opts)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KeNmNnHqaUI-","colab_type":"text"},"source":["### Short Answer"]},{"cell_type":"code","metadata":{"id":"xwyaUn7CaOtp","colab_type":"code","colab":{}},"source":["short_answer_dataset = ShortAnswerDataset(\n","    short_answer = short_answers_df,\n","    tokenizer=tokenizer,\n","    max_length=max_lenght_NQ)\n","\n","short_answer_dataloader = DataLoader(short_answer_dataset, batch_size=batch_size,num_workers=cpu_count())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"33weifEzaO7Q","colab_type":"code","colab":{}},"source":["ids = []\n","short_answer_portuguese = []\n","start_token = []\n","end_token = []\n","\n","for batch in short_answer_dataloader:\n","    #ids\n","    ids.extend(batch[3].detach().cpu().tolist()) \n","    # Start token\n","    start_token.extend(batch[4].detach().cpu().tolist()) \n","    # End token\n","    end_token.extend(batch[5].detach().cpu().tolist()) \n","    #question\n","    out = model(batch[0].to(device), batch[1].to(device))\n","    long_answer_portuguese = [fix_accent_breaks(tokenizer.decode(tokens)) for tokens in out]\n","    short_answer_portuguese.extend(long_answer_portuguese)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cnbUh1AeaPAv","colab_type":"code","colab":{}},"source":["short_answer_df_portuguese = pd.DataFrame({'ID': ids, 'SHORT_ANSWER': short_answer_portuguese, 'START_SA': start_token,'END_SA':end_token})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKadoTIf5oUl","colab_type":"code","colab":{}},"source":["short_answer_df_portuguese.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Hi0G4F20ot5","colab_type":"code","colab":{}},"source":["compression_opts = dict(method='zip', archive_name='short_answer_df_portuguese.csv') \n","short_answer_df_portuguese.to_csv('short_answer_df_portuguese.zip', index=False,compression=compression_opts)"],"execution_count":null,"outputs":[]}]}